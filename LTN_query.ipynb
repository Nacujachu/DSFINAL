{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import bs4\n",
    "import time\n",
    "\n",
    "class LTN_crawler(object):\n",
    "    def __init__(self):\n",
    "        self.author = 'Yang_nacuJachu'\n",
    "        \n",
    "    def search(self,dir_name,keyword , SYear , SMonth , SDay, EYear , EMonth , EDay):\n",
    "        \n",
    "        SYear , SMonth , SDay, EYear , EMonth , EDay = str(SYear) , str(SMonth) , str(SDay), str(EYear) , str(EMonth) , str(EDay)\n",
    "        \n",
    "        url = 'http://news.ltn.com.tw/search/?keyword='+keyword+'&conditions=and&SYear='+SYear+'&SMonth='+\\\n",
    "        SMonth+'&SDay='+SDay+'&EYear='+EYear+'&EMonth='+EMonth+'&EDay='+EDay+'&page=1'\n",
    "        \n",
    "        out_file_name = dir_name+'/' + keyword + '_' + SYear[3:4]+ '_' + SMonth+'_'+ SDay+'_'+ EYear[3:4]+'_' + EMonth+'_'+EDay+'.txt'\n",
    "        out_f = open(out_file_name , 'w',encoding='utf-8')\n",
    "        while(url):\n",
    "\n",
    "            r = requests.get(url)\n",
    "            soup = BeautifulSoup(r.text , 'html.parser')\n",
    "\n",
    "            news_urls = []\n",
    "\n",
    "            prefix = 'http://news.ltn.com.tw/'\n",
    "            k = soup.find('div','whitecon boxTitle')\n",
    "\n",
    "            nx_page = soup.find('a',{'class':'p_next'})\n",
    "            if nx_page == None:\n",
    "                url = None\n",
    "            else:\n",
    "                url = nx_page.get('href')\n",
    "\n",
    "            for t in k.find_all('a'):\n",
    "                if(t['class'] == ['tit']):\n",
    "                    Nurl = t.get('href')\n",
    "                    news_urls.append(prefix+Nurl)\n",
    "\n",
    "            \n",
    "            for news_url in news_urls :\n",
    "                cur_news_text = ''\n",
    "                cur_req = requests.get(news_url)\n",
    "                cur_soup = BeautifulSoup(cur_req.text , 'html.parser')\n",
    "                #print('--'+news_url)\n",
    "                if 'opinion' in news_url or 'entertainment' in news_url:\n",
    "                    continue\n",
    "                try:\n",
    "                    a=cur_soup.find_all('div','text')[0]\n",
    "                except:\n",
    "                    pass\n",
    "                for txt in a.find_all('p'):\n",
    "                    cur_news_text += txt.text\n",
    "                #print(cur_news_text)\n",
    "                out_f.write(cur_news_text)\n",
    "                out_f.write('\\n')\n",
    "                time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = LTN_crawler()\n",
    "\n",
    "q = '蔡英文'\n",
    "d = q+\"_自由\"\n",
    "l.search(d,q,2018,1,1,2018,3,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-208-2f4904802683>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'class'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'p_next'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'href'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "r = requests.get('http://news.ltn.com.tw/search/?keyword=%E8%94%A1%E8%8B%B1%E6%96%87&conditions=and&SYear=2018&SMonth=3&SDay=19&EYear=2018&EMonth=3&EDay=19')\n",
    "soup = BeautifulSoup(r.text,'html.parser')\n",
    "k = soup.find('a',{'class':'p_next'})\n",
    "print(k == None)\n",
    "print(k.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('http://news.ltn.com.tw/search/?keyword=%E8%94%A1%E8%8B%B1%E6%96%87&conditions=and&SYear=2018&SMonth=3&SDay=19&EYear=2018&EMonth=3&EDay=19')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(r.text,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://news.ltn.com.tw/search/?keyword=蔡英文&conditions=and&SYear=2018&SMonth=3&SDay=21&EYear=2018&EMonth=3&EDay=22&page=2\n"
     ]
    }
   ],
   "source": [
    "k = soup.find('a',{'class':'p_next'})\n",
    "print(k.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "news/politics/breakingnews/2456351\n",
      "http://news.ltn.com.tw/news/politics/breakingnews/2456351\n",
      "news/life/breakingnews/2456345\n",
      "http://news.ltn.com.tw/news/life/breakingnews/2456345\n",
      "news/local/paper/1208454\n",
      "http://news.ltn.com.tw/news/local/paper/1208454\n",
      "news/focus/paper/1208444\n",
      "http://news.ltn.com.tw/news/focus/paper/1208444\n",
      "news/local/paper/1208300\n",
      "http://news.ltn.com.tw/news/local/paper/1208300\n",
      "news/focus/breakingnews/2456290\n",
      "http://news.ltn.com.tw/news/focus/breakingnews/2456290\n",
      "news/opinion/breakingnews/2456311\n",
      "http://news.ltn.com.tw/news/opinion/breakingnews/2456311\n",
      "news/politics/breakingnews/2456028\n",
      "http://news.ltn.com.tw/news/politics/breakingnews/2456028\n",
      "news/life/breakingnews/2456068\n",
      "http://news.ltn.com.tw/news/life/breakingnews/2456068\n",
      "news/business/breakingnews/2456019\n",
      "http://news.ltn.com.tw/news/business/breakingnews/2456019\n",
      "news/business/breakingnews/2455923\n",
      "http://news.ltn.com.tw/news/business/breakingnews/2455923\n",
      "news/politics/breakingnews/2455897\n",
      "http://news.ltn.com.tw/news/politics/breakingnews/2455897\n",
      "news/politics/breakingnews/2455741\n",
      "http://news.ltn.com.tw/news/politics/breakingnews/2455741\n",
      "news/politics/breakingnews/2455714\n",
      "http://news.ltn.com.tw/news/politics/breakingnews/2455714\n",
      "news/politics/breakingnews/2455662\n",
      "http://news.ltn.com.tw/news/politics/breakingnews/2455662\n"
     ]
    }
   ],
   "source": [
    "prefix = 'http://news.ltn.com.tw/'\n",
    "for t in k.find_all('a'):\n",
    "    \n",
    "    if(t['class'] == ['tit']):\n",
    "        url = t.get('href')\n",
    "        print(t.get('href'))\n",
    "        print(prefix+url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('http://news.ltn.com.tw/news/business/breakingnews/2455923')\n",
    "soup = BeautifulSoup(r.text , 'html.parser')\n",
    "a=soup.find_all('div','text')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'〔記者李雅雯／台北報導〕基本工資審議委員會第三季會議預計將在8月中上旬召開，會議結論將攸關明年度的基本工資是否調整。現行基本工資月薪為22000元、時薪為140元，勞動部長許銘春今（12日）天指出，基本工資審議委員會第三季會議預計將在8月中上旬召開，關於是否已有預期調漲或不調漲，甚或是調漲幅度，許銘春則未多作表示。總統蔡英文六大勞動政見之一「派遣勞工專法」，由於現階段各方在部分討論區塊上仍有巨大分歧，尤其是派遣人員佔事業單位聘僱人數「3%」和「負面表列」（禁止哪些事業單位使用派遣人員）部分，勞資雙方都有不同意見。勞動部政務次長施克和認為，派遣專法相關立法程序尚須「循序漸進」，沒有共識的部分還需再溝通、討論，對於立法相關程序目前未有時程表，現階段將先以行政指導作為事業單位參考遵循的原則方向。勞動部長許銘春5月28日在立法院衛環社福委員會質詢上即表明，派遣專法「下個會期有困難」。勞動部在2014年曾擬出《派遣勞工保護法》草案送行政院審查，後來因因勞資雙方對於該案內容意見不一，此案最終退回勞動部。勞動部長許銘春。（記者李雅雯攝）'"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_text = ''\n",
    "for txt in a.find_all('p'):\n",
    "    news_text += txt.text\n",
    "news_text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
